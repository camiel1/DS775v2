{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# imports, add to this as needed\n",
    "\n",
    "# change to matplotlib notebook for classic view\n",
    "%matplotlib inline\n",
    "from scipy.optimize import dual_annealing, basinhopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Simulated Annealing for TSP with 48 cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Adapt our \"homemade\" simulated annealing code from Section 2.1 in the lesson to solve the 48 capitals TSP problem from last week.  The json file `Caps48.json` in the data folder has both the distance matrix and the coordinates of the cities for plotting.  Note the distance of typical random tour is something like 80,000,000 meters and we're looking for something under 18,000,000 meters.  Your initial temperature has to be large enough to allow large moves on this scale and you'll have to increase `max_moves_no_improve` as well.  You should plot the progress of the search, like in the lesson, and you should plot the final result on the map of the United States as we did last week (that code is given in a cell below). Included a value for the random seed so that your results are reproducible.  Report a search that gives total distance < 18,000,000 meters.  A tour that achieves the optimum distance is shown in the json file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Put your code to find the solution in the cell below.  Your output should include a convergence plot like in the lesson (best distance versus iteration and current distance versus iteration).\n",
    "\n",
    "<font color = \"blue\"> *** 4 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot the tour on the map of the U.S.  Code to do this is below.\n",
    "\n",
    "<font color = \"blue\"> *** 1 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load the data and define move and objective functions\n",
    "mapUS = Basemap(llcrnrlon=-119,\n",
    "              llcrnrlat=22,\n",
    "              urcrnrlon=-64,\n",
    "              urcrnrlat=49,\n",
    "              projection='lcc',\n",
    "              lat_1=32,\n",
    "              lat_2=45,\n",
    "              lon_0=-95)\n",
    "\n",
    "# read 48 capitals lat and lon\n",
    "with open('./data/Caps48.json', 'r') as json_file:\n",
    "    capitals = json.load(json_file)\n",
    "\n",
    "xy = np.array(capitals['Coordinates'])\n",
    "\n",
    "def plot_tour(best_tour, xy, best_dist):\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(6, 4)\n",
    "\n",
    "    # load the shape file with \"states\"\n",
    "    mapUS.readshapefile('./data/st99_d00', name='states', drawbounds=True)\n",
    "\n",
    "    loop_tour = np.append(best_tour, best_tour[0])\n",
    "    mapUS.plot(xy[:, 0], xy[:, 1], c='r', marker='o', markersize=4, linestyle='')\n",
    "    lines, = mapUS.plot(xy[loop_tour, 0],\n",
    "                      xy[loop_tour, 1],\n",
    "                      c='b',\n",
    "                      linewidth=1,\n",
    "                      linestyle='-')\n",
    "    plt.title('Best Distance {:d} km'.format(int(best_dist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on the plot of the tour do you think you have found a nearly optimal tour.  Explain why or why not.\n",
    "\n",
    "<font color = \"blue\"> *** 1 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Knapsack with simanneal package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The knapsack problem is a classical combinatorial optimization problem that will be good for practicing with the ideas of discrete local search and multistart.  Given a set of items, each with a weight and a value, determine which items to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible.  In the 0-1 version of the knapsack problem, the decision variables are binary (or boolean) and represent whether or not to include each item in the collection.  We'll start with 20 items and you need to determine the collection of items that maximizes the value and keeps the total weight up to 50 (that is $\\leq 50$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# generate random weights and values for a knapsack problem\n",
    "import numpy as np\n",
    "num_items = 20\n",
    "np.random.seed(seed=123)\n",
    "values = np.random.randint(low=5, high=50, size=num_items)\n",
    "weights = np.random.randint(low=1, high=10, size=num_items)\n",
    "max_weight = 50\n",
    "np.random.seed() # use system clock to reset the seed so future random numbers will appear random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use the `simanneal` package to apply simulated annealing to finding a good solution to this knapsack problem. Show your solution below.  We suggest using lists of booleans to represent the items included in the knapsack as we did last week.\n",
    "\n",
    "<font color = \"blue\"> *** 9 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Do you think you've found the knapsack with highest possible value (the global max)?  Why or why not?\n",
    "\n",
    "<font color = \"blue\"> *** 1 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 48 Capital TSP with Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use the DEAP genetic algorithm described in the lesson to approximate a solution to the 48 state capital TSP introduced last week.  The distance matrix (in meters) and city coordinates are in `data/Caps48.json`.  Experiment with the algorithm parameters until you can find a tour of length $\\leq$ 21,000,000 meters (21,000 kilometers).  Uncomment the random.seed() line and possibly try different seed values so that, if all the other parameters are the same, running the algorithm again will produce the same results.\n",
    "\n",
    "Put your code in the cell below. Make sure it prints out both the best tour and the tour distance.  Feel free to divide distances by 1000 to display results in kilometers.\n",
    "\n",
    "<font color = \"blue\"> *** 4 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " Make a plot of the best tour.\n",
    "\n",
    "<font color = \"blue\"> *** 1 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on the plot of the tour do you think you have found a nearly optimal tour.  Explain why or why not.\n",
    "\n",
    "<font color = \"blue\"> *** 1 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 48 Capital TSP with Genetic Algorithm and Local Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Genetic algorithms are great for exploring a large solution space, but not so good at refining the details when close to an optimal solution.  For this reason genetic algorithms are often combined with local search.  The idea is that at each generation some or all of the individuals in the population are replaced by the result of a local search.  We'll explore this by using the 2-opt local search for TSP to refine the three worst tours in each generation.  Create a new customGA() algorithm called customGA_TSP_LS() and include this code at the beginning of the while loop:\n",
    "\n",
    "```\n",
    "# replace 3 worst individuals with local searches\n",
    "pop.sort(key=lambda x:x.fitness.values,reverse=True)\n",
    "num_loc_search = 3\n",
    "for i in range(num_loc_search):\n",
    "    best_tour, best_dist, iterations = two_opt(list(pop[i]),distance_matrix)\n",
    "    pop[i] = creator.Individual(best_tour)\n",
    "    pop[i].fitness.values = (best_dist,)\n",
    "```\n",
    "This finds the three worst tours and does a 2-opt local search on each and then replaces the results in the population.\n",
    "\n",
    "You'll also need this version of the 2-opt search that uses the distance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sub_tour_reversal_ij(tour,i,j):\n",
    "    n = len(tour)\n",
    "    return (np.concatenate((tour[0:i], tour[j:-n + i - 1:-1], tour[j + 1:n])).astype(int))\n",
    "\n",
    "def tour_distance(individual, dist_mat):\n",
    "    distance = dist_mat[individual[-1]][individual[0]]\n",
    "    for gene1, gene2 in zip(individual[0:-1], individual[1:]):\n",
    "        distance += dist_mat[gene1][gene2]\n",
    "    return (distance,) \n",
    "\n",
    "def two_opt(start_tour,dist_mat):\n",
    "    num_cities = len(start_tour)\n",
    "    current_dist = tour_distance(start_tour, dist_mat)[0]\n",
    "    best_tour = start_tour\n",
    "    best_dist = current_dist\n",
    "\n",
    "    improvement = True\n",
    "    iterations = 0\n",
    "    while improvement:\n",
    "        improvement = False\n",
    "        for i in range(num_cities - 1):\n",
    "            for j in range(i + 1, num_cities):\n",
    "                iterations += 1\n",
    "                new_tour = sub_tour_reversal_ij(best_tour, i, j)\n",
    "                new_dist = tour_distance(new_tour, dist_mat)[0]\n",
    "                if new_dist < best_dist:\n",
    "                    best_tour = new_tour\n",
    "                    best_dist = new_dist\n",
    "                    improvement = True\n",
    "    return best_tour, best_dist, iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Put your customGA_TSP_LS function in the next cell. You can run this version of the algorithm with a much smaller population and for far fewer iterations.  Find a tour of length $\\leq$ 17,500 km. Use a random number seed for reproducibility.  Put your code in the next cell and print out the best distance and tour.\n",
    "\n",
    "\n",
    "<font color = \"blue\"> *** 6 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot the best tour below. \n",
    "\n",
    "<font color = \"blue\"> *** 1 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Is this a good tour?  Explain.\n",
    "\n",
    "<font color = \"blue\"> *** 1 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Knapsack problem with GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use the DEAP framework to build a genetic algorithm to solve the knapsack problem (same as in problem 2).  \n",
    "\n",
    "The individuals should be lists of booleans:\n",
    "```\n",
    "def create_individual(n):\n",
    "    return random.choices([True, False], k=n)\n",
    "```\n",
    "\n",
    "Use tournament selection and one point crossover.  For mutation flip booleans at random with this:\n",
    "```\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=.1)\n",
    "```\n",
    "\n",
    "Here is a non-tuple version of a fitness function to get you started.  Notice that it includes a penalty term that penalizes if the knapsack is over the maximum weight.\n",
    "\n",
    "```\n",
    "def knapsack_value(x, values, weights, max_tot_weight):\n",
    "    # x is a vector of booleans of which items to include\n",
    "    tot_value = sum(values[x])\n",
    "    penalty = sum(values)*min( max_tot_weight - sum(weights[x]), 0) \n",
    "    return tot_value+penalty\n",
    "```\n",
    "    \n",
    "Put your code in the cell below.  Use random.seed() to make reproducible results.\n",
    "\n",
    "<font color = \"blue\"> *** 9 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Do you think you've found the knapsack with highest possible value (the global max)?  Why or why not?\n",
    "\n",
    "<font color = \"blue\"> *** 1 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 30 dimensional Rastrigin Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "30 dimensions means that each individual or potential solution is a list of 30 real numbers each between -5.12 and 5.12.  Use either `simanneal` or `DEAP` (or both) to find the global optimum value (it's zero and happens when $x_1 = x_2 = \\ldots = x_{30}$). Use random number seeds to make your search reproducible - `random.seed()` and/or `numpy.random.seed`, you may even need to set both since DEAP and simanneal both use `random` while we've been using `np.random` for generating moves and picking starting points for continuous optimization.   You should add a global variable to count the number of times you call the Rastrigin function and report that number as well.\n",
    "\n",
    "<font color = \"blue\"> *** 8 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# rastrigin definition\n",
    "def rastrigin(x):\n",
    "    x = np.array(x) # force a numpy arrray here so that the math below works\n",
    "    # pass a single vector of length n (=dim) to evaluate Rastrigin\n",
    "    return sum(x**2 + 10 - 10 * np.cos(2 * np.pi * x))\n",
    "\n",
    "# add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Scipy.optimize also includes two optimization routines for continuous optimization that are similar to simulated annealing.  Both dual_annealing and basinhopping combine local search with an annealing-like process.  Run the code in the next two cells and then write about your results at the bottom.  You can try changing maxiter in dual_annealing and niter in basinhopping if you don't find the global minimum right away. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run this cell for dual_annealing on 30D Rastrigin (mostly thanks to Deanna S.)\n",
    "# first execute cell with rastrigin definition above, and imports cell at top of notebook\n",
    "dim = 30\n",
    "bounds = [(-5.12, 5.12) for i in range(dim)]\n",
    "\n",
    "#this tells scipy minimize which method to use\n",
    "minimizer_kwargs = {\"method\": \"TNC\"}\n",
    "\n",
    "#define a function so we can see what's happening\n",
    "log = []\n",
    "acceptedVal = []\n",
    "def print_fun(x, f, accepted):\n",
    "        log.append(f)\n",
    "        acceptedVal.append(int(accepted))\n",
    "\n",
    "# call dual_annealing\n",
    "result = dual_annealing(rastrigin, bounds, maxiter = 200, callback=print_fun)\n",
    "\n",
    "print(\n",
    "    'The lowest value of {:0.4f} took {:d} iterations and {:d} function evaluations.'\n",
    "    .format(result.fun, result.nit, result.nfev))\n",
    "print('The location of this lowest value is:')\n",
    "print(result.x)\n",
    "\n",
    "iterations = [i for i in range(len(log))]\n",
    "import matplotlib.pyplot as plt\n",
    "# plot search convergence\n",
    "fig = plt.figure(figsize=(5, 3.5))\n",
    "line_min, = plt.plot(iterations, log, label='Min. Val.')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accepted function value')\n",
    "plt.legend(handles=[line_min])\n",
    "plt.title('Smallest value Found: {:4f}'.format(min(log)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run this cell for basinhopping on 30D Rastrigin (mostly thanks to Deanna S.)\n",
    "# first execute cell with rastrigin definition above, and imports cell at top of notebook\n",
    "\n",
    "#set up the variables and initial vector\n",
    "low = -5.12\n",
    "high = 5.12\n",
    "dim = 30\n",
    "x0 = np.random.uniform(low=-5.12,high=5.12,size=dim)\n",
    "\n",
    "#We need to use bounds, so set up a custom MyBounds object\n",
    "class MyBounds(object):\n",
    "    def __init__(self, xmax=[high] * dim, xmin=[low] * dim ):\n",
    "        self.xmax = np.array(xmax)\n",
    "        self.xmin = np.array(xmin)\n",
    "    def __call__(self, **kwargs):\n",
    "        x = kwargs[\"x_new\"]\n",
    "        tmax = bool(np.all(x <= self.xmax))\n",
    "        tmin = bool(np.all(x >= self.xmin))\n",
    "        return tmax and tmin\n",
    "\n",
    "#create an instance of the bounds object\n",
    "mybounds = MyBounds()\n",
    "\n",
    "#this tells scipy minimize which method to use\n",
    "minimizer_kwargs = {\"method\": \"TNC\"}\n",
    "\n",
    "#define a function so we can see what's happening\n",
    "log = []\n",
    "acceptedVal = []\n",
    "def print_fun(x, f, accepted):\n",
    "        log.append(f)\n",
    "        acceptedVal.append(int(accepted))\n",
    "\n",
    "#run it\n",
    "result = basinhopping(rastrigin, x0, minimizer_kwargs=minimizer_kwargs,\n",
    "                   niter=200, accept_test=mybounds,\n",
    "                   callback=print_fun)\n",
    "\n",
    "print(\n",
    "    'The lowest value of {:0.4f} took {:d} iterations and {:d} function evaluations.'\n",
    "    .format(result.fun, result.nit, result.nfev))\n",
    "print('The location of this lowest value is:')\n",
    "print(result.x)\n",
    "\n",
    "iterations = [i for i in range(len(log))]\n",
    "import matplotlib.pyplot as plt\n",
    "# plot search convergence\n",
    "fig = plt.figure(figsize=(5, 3.5))\n",
    "line_min, = plt.plot(iterations, log, label='Min. Val.')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accepted function value')\n",
    "plt.legend(handles=[line_min])\n",
    "plt.title('Smallest value Found: {:4f}'.format(min(log)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How does your optimization result (from DEAP and/or simanneal) compare to the results found by dual_annealing and basinhopping in terms of accuracy and efficiency?  Give a brief summary and comparision of the results.\n",
    "\n",
    "<font color = \"blue\"> *** 2 points -  answer in cell below *** (don't delete this cell) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
